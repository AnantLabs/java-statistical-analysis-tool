package jsat.distributions.kernels;

import jsat.linear.Vec;

/**
 * Some kernels can be more expensive to evaluate than others, which can be 
 * particularly problematic during training time. This interface provides more 
 * expensive kernels to expose and use a cache of values to accelerate kernel 
 * computation when working with a fixed training set. The cache should be 
 * linear in size compared to the training set size. This assumption is made for
 * sanity in memory use, and is not enforcable. <br><br>
 * This cache should not be used to store an explicit kernel map for every 
 * combination, which is caching all results instead of accelerating results. 
 * Such measures should be handled by the underlying algorithm. 
 * 
 * @author Edward Raff
 */
public interface CacheAcceleratedKernel extends KernelTrick
{
    /**
     * Creates a new array of cache values from a given list of training set 
     * vectors
     * @param trainingSet the array of training set vectors
     * @return an array of cache values that may be used by this kernel
     */
    public double[] getCache(Vec[] trainingSet);
    
    /**
     * Produces the correct kernel evaluation given the training set and the 
     * cache generated by {@link #getCache(jsat.linear.Vec[]) }. The training 
     * vectors should be in the same order. 
     * 
     * @param a the index of the first training vector
     * @param b the index of the second training vector
     * @param trainingSet the array of training set vectors
     * @param cache the double array of cache values generated by this kernel 
     * for the given training set
     * @return the same kernel evaluation result as 
     * {@link #eval(jsat.linear.Vec, jsat.linear.Vec) }
     */
    public double eval(int a, int b, Vec[] trainingSet, double[] cache);
    
    /**
     * Performs an efficient summation of kernel products of the form <br>
     * <big>&#8721;</big> &alpha;<sub>i</sub> k(x<sub>i</sub>, y) <br>
     * where <i>x</i> are the final set of vectors, and <i>&alpha;</i> the 
     * associated scalar multipliers
     * 
     * @param finalSet the final set of vectors
     * @param cache the cache associated with the final set of vectors
     * @param alpha the coefficients associated with each vector
     * @param y the vector to perform the summed kernel products against
     * @param start the starting index (inclusive) to sum from
     * @param end the ending index (exclusive) to sum from
     * @return the sum of the multiplied kernel products
     */
    public double evalSum(Vec[] finalSet, double[] cache, double[] alpha, Vec y, int start, int end);
    
}
